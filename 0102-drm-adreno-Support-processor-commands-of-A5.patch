From 73cbcda5735abf12faad5bbfe7e647ecbd9efe5b Mon Sep 17 00:00:00 2001
From: Kasin Li <donglil@codeaurora.org>
Date: Fri, 10 Jun 2016 17:02:58 -0700
Subject: [PATCH 102/105] drm: adreno: Support processor commands of A5

Add new register define for adreno5. And type of CP package changed from
Adreno 4 to Adreno 5.

Change-Id: I65d4f43a082942cad8b0f3d877679f621ba5aa8c
Signed-off-by: Kasin Li <donglil@codeaurora.org>
---
 drivers/gpu/drm/msm/adreno/adreno_gpu.c     | 153 ++++++++----------
 drivers/gpu/drm/msm/adreno/adreno_gpu.h     | 241 ++++++++++++++++++++++++----
 drivers/gpu/drm/msm/adreno/adreno_pm4.xml.h |   3 +-
 3 files changed, 281 insertions(+), 116 deletions(-)

diff --git a/drivers/gpu/drm/msm/adreno/adreno_gpu.c b/drivers/gpu/drm/msm/adreno/adreno_gpu.c
index 2273d75..4f9cfb9 100644
--- a/drivers/gpu/drm/msm/adreno/adreno_gpu.c
+++ b/drivers/gpu/drm/msm/adreno/adreno_gpu.c
@@ -21,9 +21,6 @@
 #include "msm_gem.h"
 #include "msm_mmu.h"
 
-#define RB_SIZE    SZ_32K
-#define RB_BLKSIZE 16
-
 int adreno_get_param(struct msm_gpu *gpu, uint32_t param, uint64_t *value)
 {
 	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
@@ -53,9 +50,9 @@ int adreno_get_param(struct msm_gpu *gpu, uint32_t param, uint64_t *value)
 int adreno_hw_init(struct msm_gpu *gpu)
 {
 	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
-	int ret;
+	int ret = 0;
 
-	DBG("%s", gpu->name);
+	DRM_INFO("%s", gpu->name);
 
 	ret = msm_gem_get_iova(gpu->rb->bo, gpu->id, &gpu->rb_iova);
 	if (ret) {
@@ -64,22 +61,20 @@ int adreno_hw_init(struct msm_gpu *gpu)
 		return ret;
 	}
 
+	/* ring buffer address should be 32 bytes aligned */
+	if (gpu->rb_iova & 0x1F)
+		DRM_ERROR("ring buffer must be 32 bytes aligned\n");
+
 	/* Setup REG_CP_RB_CNTL: */
 	adreno_gpu_write(adreno_gpu, REG_ADRENO_CP_RB_CNTL,
 			/* size is log2(quad-words): */
-			AXXX_CP_RB_CNTL_BUFSZ(ilog2(gpu->rb->size / 8)) |
-			AXXX_CP_RB_CNTL_BLKSZ(ilog2(RB_BLKSIZE / 8)));
+			AXXX_CP_RB_CNTL_BUFSZ(ilog2(gpu->rb->size / 8)));
 
 	/* Setup ringbuffer address: */
-	adreno_gpu_write(adreno_gpu, REG_ADRENO_CP_RB_BASE, gpu->rb_iova);
-	adreno_gpu_write(adreno_gpu, REG_ADRENO_CP_RB_RPTR_ADDR,
-			rbmemptr(adreno_gpu, rptr));
-
-	/* Setup scratch/timestamp: */
-	adreno_gpu_write(adreno_gpu, REG_ADRENO_SCRATCH_ADDR,
-			rbmemptr(adreno_gpu, fence));
-
-	adreno_gpu_write(adreno_gpu, REG_ADRENO_SCRATCH_UMSK, 0x1);
+	adreno_gpu_write(adreno_gpu, REG_ADRENO_CP_RB_BASE,
+			lower_32_bits(gpu->rb_iova));
+	adreno_gpu_write(adreno_gpu, REG_ADRENO_CP_RB_BASE_HI,
+			upper_32_bits(gpu->rb_iova));
 
 	return 0;
 }
@@ -125,7 +120,7 @@ int adreno_submit(struct msm_gpu *gpu, struct msm_gem_submit *submit,
 	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
 	struct msm_drm_private *priv = gpu->dev->dev_private;
 	struct msm_ringbuffer *ring = gpu->rb;
-	unsigned i, ibs = 0;
+	unsigned i;
 
 	for (i = 0; i < submit->nr_cmds; i++) {
 		switch (submit->cmd[i].type) {
@@ -137,65 +132,22 @@ int adreno_submit(struct msm_gpu *gpu, struct msm_gem_submit *submit,
 			if (priv->lastctx == ctx)
 				break;
 		case MSM_SUBMIT_CMD_BUF:
-			OUT_PKT3(ring, CP_INDIRECT_BUFFER_PFD, 2);
-			OUT_RING(ring, submit->cmd[i].iova);
+			OUT_PKT7(ring, CP_INDIRECT_BUFFER_PFE, 3);
+			OUT_RING(ring, lower_32_bits(submit->cmd[i].iova));
+			OUT_RING(ring, upper_32_bits(submit->cmd[i].iova));
 			OUT_RING(ring, submit->cmd[i].size);
-			ibs++;
 			break;
 		}
 	}
 
-	/* on a320, at least, we seem to need to pad things out to an
-	 * even number of qwords to avoid issue w/ CP hanging on wrap-
-	 * around:
-	 */
-	if (ibs % 2)
-		OUT_PKT2(ring);
-
-	OUT_PKT0(ring, REG_AXXX_CP_SCRATCH_REG2, 1);
-	OUT_RING(ring, submit->fence);
-
-	if (adreno_is_a3xx(adreno_gpu) || adreno_is_a4xx(adreno_gpu)) {
-		/* Flush HLSQ lazy updates to make sure there is nothing
-		 * pending for indirect loads after the timestamp has
-		 * passed:
-		 */
-		OUT_PKT3(ring, CP_EVENT_WRITE, 1);
-		OUT_RING(ring, HLSQ_FLUSH);
+	OUT_PKT7(ring, CP_WAIT_FOR_IDLE, 0);
 
-		OUT_PKT3(ring, CP_WAIT_FOR_IDLE, 1);
-		OUT_RING(ring, 0x00000000);
-	}
-
-	OUT_PKT3(ring, CP_EVENT_WRITE, 3);
+	OUT_PKT7(ring, CP_EVENT_WRITE, 4);
 	OUT_RING(ring, CACHE_FLUSH_TS);
-	OUT_RING(ring, rbmemptr(adreno_gpu, fence));
+	OUT_RING(ring, lower_32_bits(rbmemptr(adreno_gpu, fence)));
+	OUT_RING(ring, upper_32_bits(rbmemptr(adreno_gpu, fence)));
 	OUT_RING(ring, submit->fence);
 
-	/* we could maybe be clever and only CP_COND_EXEC the interrupt: */
-	OUT_PKT3(ring, CP_INTERRUPT, 1);
-	OUT_RING(ring, 0x80000000);
-
-	/* Workaround for missing irq issue on 8x16/a306.  Unsure if the
-	 * root cause is a platform issue or some a306 quirk, but this
-	 * keeps things humming along:
-	 */
-	if (adreno_is_a306(adreno_gpu)) {
-		OUT_PKT3(ring, CP_WAIT_FOR_IDLE, 1);
-		OUT_RING(ring, 0x00000000);
-		OUT_PKT3(ring, CP_INTERRUPT, 1);
-		OUT_RING(ring, 0x80000000);
-	}
-
-#if 0
-	if (adreno_is_a3xx(adreno_gpu)) {
-		/* Dummy set-constant to trigger context rollover */
-		OUT_PKT3(ring, CP_SET_CONSTANT, 2);
-		OUT_RING(ring, CP_REG(REG_A3XX_HLSQ_CL_KERNEL_GROUP_X_REG));
-		OUT_RING(ring, 0x00000000);
-	}
-#endif
-
 	gpu->funcs->flush(gpu);
 
 	return 0;
@@ -208,18 +160,18 @@ void adreno_flush(struct msm_gpu *gpu)
 
 	/* ensure writes to ringbuffer have hit system memory: */
 	mb();
-
 	adreno_gpu_write(adreno_gpu, REG_ADRENO_CP_RB_WPTR, wptr);
 }
 
-void adreno_idle(struct msm_gpu *gpu)
+void drma_idle(struct msm_gpu *gpu)
 {
 	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
 	uint32_t wptr = get_wptr(gpu->rb);
 
 	/* wait for CP to drain ringbuffer: */
 	if (spin_until(adreno_gpu->memptrs->rptr == wptr))
-		DRM_ERROR("%s: timeout waiting to drain ringbuffer!\n", gpu->name);
+		DRM_ERROR("%s: timeout waiting to drain ringbuffer!\n",
+			  gpu->name);
 
 	/* TODO maybe we need to reset GPU here to recover from hang? */
 }
@@ -271,19 +223,19 @@ void adreno_dump_info(struct msm_gpu *gpu)
 	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
 	int i;
 
-	printk("revision: %d (%d.%d.%d.%d)\n",
+	pr_info("revision: %d (%d.%d.%d.%d)\n",
 			adreno_gpu->info->revn, adreno_gpu->rev.core,
 			adreno_gpu->rev.major, adreno_gpu->rev.minor,
 			adreno_gpu->rev.patchid);
 
-	printk("fence:    %d/%d\n", adreno_gpu->memptrs->fence,
+	pr_info("fence:    %d/%d\n", adreno_gpu->memptrs->fence,
 			gpu->submitted_fence);
-	printk("rptr:     %d\n", adreno_gpu->memptrs->rptr);
-	printk("wptr:     %d\n", adreno_gpu->memptrs->wptr);
-	printk("rb wptr:  %d\n", get_wptr(gpu->rb));
+	pr_info("rptr:     %d\n", adreno_gpu->memptrs->rptr);
+	pr_info("wptr:     %d\n", adreno_gpu->memptrs->wptr);
+	pr_info("rb wptr:  %d\n", get_wptr(gpu->rb));
 
 	for (i = 0; i < 8; i++) {
-		printk("CP_SCRATCH_REG%d: %u\n", i,
+		pr_info("CP_SCRATCH_REG%d: %u\n", i,
 			gpu_read(gpu, REG_AXXX_CP_SCRATCH_REG0 + i));
 	}
 }
@@ -295,7 +247,7 @@ void adreno_dump(struct msm_gpu *gpu)
 	int i;
 
 	/* dump these out in a form that can be parsed by demsm: */
-	printk("IO:region %s 00000000 00020000\n", gpu->name);
+	pr_info("IO:region %s 00000000 00020000\n", gpu->name);
 	for (i = 0; adreno_gpu->registers[i] != ~0; i += 2) {
 		uint32_t start = adreno_gpu->registers[i];
 		uint32_t end   = adreno_gpu->registers[i+1];
@@ -303,24 +255,44 @@ void adreno_dump(struct msm_gpu *gpu)
 
 		for (addr = start; addr <= end; addr++) {
 			uint32_t val = gpu_read(gpu, addr);
-			printk("IO:R %08x %08x\n", addr<<2, val);
+
+			pr_info("IO:R %08x %08x\n", addr<<2, val);
 		}
 	}
 }
 
 static uint32_t ring_freewords(struct msm_gpu *gpu)
 {
-	struct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);
 	uint32_t size = gpu->rb->size / 4;
 	uint32_t wptr = get_wptr(gpu->rb);
-	uint32_t rptr = adreno_gpu->memptrs->rptr;
-	return (rptr + (size - 1) - wptr) % size;
+
+	return size - wptr - 1;
+}
+
+/*
+ * TODO next stage, remove wait on the tail of ring buffer.
+ */
+static int rb_check_and_split(struct msm_gpu *gpu, uint32_t ndwords)
+{
+	uint32_t size = gpu->rb->size / 4;
+	uint32_t wptr = get_wptr(gpu->rb);
+
+	if ((wptr + ndwords) < size-1)
+		return 0;
+
+	OUT_RING(gpu->rb, cp_pkt7(CP_NOP, (size - wptr - 1)));
+	gpu->rb->cur = gpu->rb->start;
+	gpu->funcs->flush(gpu);
+	gpu->funcs->idle(gpu);
+	return 1;
 }
 
 void adreno_wait_ring(struct msm_gpu *gpu, uint32_t ndwords)
 {
+	rb_check_and_split(gpu, ndwords);
 	if (spin_until(ring_freewords(gpu) >= ndwords))
-		DRM_ERROR("%s: timeout waiting for ringbuffer space\n", gpu->name);
+		DRM_ERROR("%s: timeout waiting for ringbuffer space\n",
+			  gpu->name);
 }
 
 static const char *iommu_ports[] = {
@@ -329,7 +301,8 @@ static const char *iommu_ports[] = {
 };
 
 int adreno_gpu_init(struct drm_device *drm, struct platform_device *pdev,
-		struct adreno_gpu *adreno_gpu, const struct adreno_gpu_funcs *funcs)
+		struct adreno_gpu *adreno_gpu,
+		const struct adreno_gpu_funcs *funcs)
 {
 	struct adreno_platform_config *config = pdev->dev.platform_data;
 	struct msm_gpu *gpu = &adreno_gpu->base;
@@ -353,19 +326,21 @@ int adreno_gpu_init(struct drm_device *drm, struct platform_device *pdev,
 			gpu->fast_rate, gpu->slow_rate, gpu->bus_freq);
 
 	ret = msm_gpu_init(drm, pdev, &adreno_gpu->base, &funcs->base,
-			adreno_gpu->info->name, "kgsl_3d0_reg_memory", "kgsl_3d0_irq",
-			RB_SIZE);
+			   adreno_gpu->info->name,
+			   "kgsl_3d0_reg_memory", "kgsl_3d0_irq");
 	if (ret)
 		return ret;
 
-	ret = request_firmware(&adreno_gpu->pm4, adreno_gpu->info->pm4fw, drm->dev);
+	ret = request_firmware(&adreno_gpu->pm4,
+			       adreno_gpu->info->pm4fw, drm->dev);
 	if (ret) {
 		dev_err(drm->dev, "failed to load %s PM4 firmware: %d\n",
 				adreno_gpu->info->pm4fw, ret);
 		return ret;
 	}
 
-	ret = request_firmware(&adreno_gpu->pfp, adreno_gpu->info->pfpfw, drm->dev);
+	ret = request_firmware(&adreno_gpu->pfp,
+			adreno_gpu->info->pfpfw, drm->dev);
 	if (ret) {
 		dev_err(drm->dev, "failed to load %s PFP firmware: %d\n",
 				adreno_gpu->info->pfpfw, ret);
@@ -416,5 +391,9 @@ void adreno_gpu_cleanup(struct adreno_gpu *gpu)
 	}
 	release_firmware(gpu->pm4);
 	release_firmware(gpu->pfp);
+	if (gpu->pm4_bo)
+		msm_gem_free_object(gpu->pm4_bo);
+	if (gpu->pfp_bo)
+		msm_gem_free_object(gpu->pfp_bo);
 	msm_gpu_cleanup(&gpu->base);
 }
diff --git a/drivers/gpu/drm/msm/adreno/adreno_gpu.h b/drivers/gpu/drm/msm/adreno/adreno_gpu.h
index 27ba16a..f51f486 100644
--- a/drivers/gpu/drm/msm/adreno/adreno_gpu.h
+++ b/drivers/gpu/drm/msm/adreno/adreno_gpu.h
@@ -27,7 +27,10 @@
 #include "adreno_common.xml.h"
 #include "adreno_pm4.xml.h"
 
+#define ADRENO_REG_UNUSED	0xFFFFFFFF
+#define ADRENO_REG_SKIP	0xFFFFFFFE
 #define REG_ADRENO_DEFINE(_offset, _reg) [_offset] = (_reg) + 1
+
 /**
  * adreno_regs: List of registers that are used in across all
  * 3D devices. Each device type has different offset value for the same
@@ -36,21 +39,26 @@
  */
 enum adreno_regs {
 	REG_ADRENO_CP_DEBUG,
+	REG_ADRENO_CP_CNTL,		/* added in a5 */
 	REG_ADRENO_CP_ME_RAM_WADDR,
 	REG_ADRENO_CP_ME_RAM_DATA,
 	REG_ADRENO_CP_PFP_UCODE_DATA,
 	REG_ADRENO_CP_PFP_UCODE_ADDR,
 	REG_ADRENO_CP_WFI_PEND_CTR,
 	REG_ADRENO_CP_RB_BASE,
+	REG_ADRENO_CP_RB_BASE_HI,	/* added in a5 */
 	REG_ADRENO_CP_RB_RPTR_ADDR,
+	REG_ADRENO_CP_RB_RPTR_ADDR_HI,
 	REG_ADRENO_CP_RB_RPTR,
 	REG_ADRENO_CP_RB_WPTR,
 	REG_ADRENO_CP_PROTECT_CTRL,
 	REG_ADRENO_CP_ME_CNTL,
 	REG_ADRENO_CP_RB_CNTL,
 	REG_ADRENO_CP_IB1_BASE,
+	REG_ADRENO_CP_IB1_BASE_HI,	/* added in a5 */
 	REG_ADRENO_CP_IB1_BUFSZ,
 	REG_ADRENO_CP_IB2_BASE,
+	REG_ADRENO_CP_IB2_BASE_HI,	/* added in a5 */
 	REG_ADRENO_CP_IB2_BUFSZ,
 	REG_ADRENO_CP_TIMESTAMP,
 	REG_ADRENO_CP_ME_RAM_RADDR,
@@ -63,14 +71,21 @@ enum adreno_regs {
 	REG_ADRENO_CP_MEQ_DATA,
 	REG_ADRENO_CP_HW_FAULT,
 	REG_ADRENO_CP_PROTECT_STATUS,
-	REG_ADRENO_SCRATCH_ADDR,
-	REG_ADRENO_SCRATCH_UMSK,
-	REG_ADRENO_SCRATCH_REG2,
+
+	/* added in a5 */
+	REG_ADRENO_CP_PROTECT_REG_0,
+	REG_ADRENO_CP_PREEMPT,
+	REG_ADRENO_CP_PREEMPT_DEBUG,
+	REG_ADRENO_CP_PREEMPT_DISABLE,
+	REG_ADRENO_CP_CONTEXT_SWITCH_SMMU_INFO_LO,
+	REG_ADRENO_CP_CONTEXT_SWITCH_SMMU_INFO_HI,
 	REG_ADRENO_RBBM_STATUS,
+	REG_ADRENO_RBBM_STATUS3,	/* added in a5 */
 	REG_ADRENO_RBBM_PERFCTR_CTL,
 	REG_ADRENO_RBBM_PERFCTR_LOAD_CMD0,
 	REG_ADRENO_RBBM_PERFCTR_LOAD_CMD1,
 	REG_ADRENO_RBBM_PERFCTR_LOAD_CMD2,
+	REG_ADRENO_RBBM_PERFCTR_LOAD_CMD3,	/* added in a5 */
 	REG_ADRENO_RBBM_PERFCTR_PWR_1_LO,
 	REG_ADRENO_RBBM_INT_0_MASK,
 	REG_ADRENO_RBBM_INT_0_STATUS,
@@ -79,6 +94,11 @@ enum adreno_regs {
 	REG_ADRENO_RBBM_AHB_CMD,
 	REG_ADRENO_RBBM_INT_CLEAR_CMD,
 	REG_ADRENO_RBBM_SW_RESET_CMD,
+
+	/* added in a5 */
+	REG_ADRENO_RBBM_BLOCK_SW_RESET_CMD,
+	REG_ADRENO_RBBM_BLOCK_SW_RESET_CMD2,
+
 	REG_ADRENO_RBBM_CLOCK_CTL,
 	REG_ADRENO_RBBM_AHB_ME_SPLIT_STATUS,
 	REG_ADRENO_RBBM_AHB_PFP_SPLIT_STATUS,
@@ -99,9 +119,45 @@ enum adreno_regs {
 	REG_ADRENO_UCHE_INVALIDATE0,
 	REG_ADRENO_RBBM_PERFCTR_LOAD_VALUE_LO,
 	REG_ADRENO_RBBM_PERFCTR_LOAD_VALUE_HI,
+
+	/* added in a5 */
+	REG_ADRENO_RBBM_SECVID_TRUST_CONTROL,
+	REG_ADRENO_RBBM_SECVID_TRUST_CONFIG,
+	REG_ADRENO_RBBM_SECVID_TSB_CONTROL,
+	REG_ADRENO_RBBM_SECVID_TSB_TRUSTED_BASE,
+	REG_ADRENO_RBBM_SECVID_TSB_TRUSTED_BASE_HI,
+	REG_ADRENO_RBBM_SECVID_TSB_TRUSTED_SIZE,
+	REG_ADRENO_RBBM_ALWAYSON_COUNTER_LO,
+	REG_ADRENO_RBBM_ALWAYSON_COUNTER_HI,
+	REG_ADRENO_VBIF_XIN_HALT_CTRL0,
+	REG_ADRENO_VBIF_XIN_HALT_CTRL1,
+	REG_ADRENO_VBIF_VERSION,
+
 	REG_ADRENO_REGISTER_MAX,
 };
 
+enum adreno_version {
+	ADRENO_REV_UNKNOWN = 0,
+	ADRENO_REV_A304 = 304,
+	ADRENO_REV_A305 = 305,
+	ADRENO_REV_A305C = 306,
+	ADRENO_REV_A306 = 307,
+	ADRENO_REV_A306A = 308,
+	ADRENO_REV_A310 = 310,
+	ADRENO_REV_A320 = 320,
+	ADRENO_REV_A330 = 330,
+	ADRENO_REV_A305B = 335,
+	ADRENO_REV_A405 = 405,
+	ADRENO_REV_A418 = 418,
+	ADRENO_REV_A420 = 420,
+	ADRENO_REV_A430 = 430,
+	ADRENO_REV_A505 = 505,
+	ADRENO_REV_A506 = 506,
+	ADRENO_REV_A510 = 510,
+	ADRENO_REV_A530 = 530,
+	ADRENO_REV_A540 = 540,
+};
+
 struct adreno_rev {
 	uint8_t  core;
 	uint8_t  major;
@@ -121,6 +177,8 @@ struct adreno_info {
 	uint32_t revn;
 	const char *name;
 	const char *pm4fw, *pfpfw;
+	const char *zap_name;
+	const char *regfw_name;
 	uint32_t gmem;
 	struct msm_gpu *(*init)(struct drm_device *dev);
 };
@@ -128,9 +186,9 @@ struct adreno_info {
 const struct adreno_info *adreno_info(struct adreno_rev rev);
 
 struct adreno_rbmemptrs {
-	volatile uint32_t rptr;
-	volatile uint32_t wptr;
-	volatile uint32_t fence;
+	uint32_t rptr;
+	uint32_t wptr;
+	uint32_t fence;
 };
 
 struct adreno_gpu {
@@ -147,6 +205,16 @@ struct adreno_gpu {
 	/* firmware: */
 	const struct firmware *pm4, *pfp;
 
+	size_t pm4_size;
+	unsigned int pm4_version;
+	struct drm_gem_object *pm4_bo;
+	void *pm4_vaddr;
+
+	size_t pfp_size;
+	unsigned int pfp_version;
+	struct drm_gem_object *pfp_bo;
+	void *pfp_vaddr;
+
 	/* ringbuffer rptr/wptr: */
 	// TODO should this be in msm_ringbuffer?  I think it would be
 	// different for z180..
@@ -167,11 +235,14 @@ struct adreno_gpu {
 struct adreno_platform_config {
 	struct adreno_rev rev;
 	uint32_t fast_rate, slow_rate, bus_freq;
+	struct drma_iommu iommu;
 #ifdef CONFIG_MSM_BUS_SCALING
 	struct msm_bus_scale_pdata *bus_scale_table;
 #endif
 };
 
+#define ADRENO_UCHE_GMEM_BASE	0x100000
+
 #define ADRENO_IDLE_TIMEOUT msecs_to_jiffies(1000)
 
 #define spin_until(X) ({                                   \
@@ -192,42 +263,55 @@ static inline bool adreno_is_a3xx(struct adreno_gpu *gpu)
 	return (gpu->revn >= 300) && (gpu->revn < 400);
 }
 
-static inline bool adreno_is_a305(struct adreno_gpu *gpu)
+
+static inline int adreno_pre_a5xx(struct adreno_gpu *gpu)
+{
+	return gpu->revn < 500;
+}
+
+static inline int adreno_is_a505_or_a506(struct adreno_gpu *gpu)
+{
+	return (gpu->revn == 505) || (gpu->revn == 506);
+}
+
+static inline int adreno_is_a510(struct adreno_gpu *gpu)
 {
-	return gpu->revn == 305;
+	return gpu->revn == 510;
 }
 
-static inline bool adreno_is_a306(struct adreno_gpu *gpu)
+static inline int adreno_is_a530(struct adreno_gpu *gpu)
 {
-	/* yes, 307, because a305c is 306 */
-	return gpu->revn == 307;
+	return gpu->revn == 530;
 }
 
-static inline bool adreno_is_a320(struct adreno_gpu *gpu)
+static inline int adreno_is_a530v1(struct adreno_gpu *gpu)
 {
-	return gpu->revn == 320;
+	return (gpu->revn == 530) && (gpu->rev.patchid == 0);
 }
 
-static inline bool adreno_is_a330(struct adreno_gpu *gpu)
+static inline int adreno_is_a530v2(struct adreno_gpu *gpu)
 {
-	return gpu->revn == 330;
+	return (gpu->revn == 530) && (gpu->rev.patchid == 1);
 }
 
-static inline bool adreno_is_a330v2(struct adreno_gpu *gpu)
+static inline int adreno_is_a530v3(struct adreno_gpu *gpu)
 {
-	return adreno_is_a330(gpu) && (gpu->rev.patchid > 0);
+	return (gpu->revn == 530) && (gpu->rev.patchid == 2);
 }
 
-static inline bool adreno_is_a4xx(struct adreno_gpu *gpu)
+static inline int adreno_is_a540(struct adreno_gpu *gpu)
 {
-	return (gpu->revn >= 400) && (gpu->revn < 500);
+	return gpu->revn == 540;
 }
 
-static inline int adreno_is_a420(struct adreno_gpu *gpu)
+
+static inline int adreno_is_a540v1(struct adreno_gpu *gpu)
 {
-	return gpu->revn == 420;
+	return (gpu->revn == 540) || (gpu->rev.patchid == 0);
 }
 
+extern bool hang_debug;
+
 int adreno_get_param(struct msm_gpu *gpu, uint32_t param, uint64_t *value);
 int adreno_hw_init(struct msm_gpu *gpu);
 uint32_t adreno_last_fence(struct msm_gpu *gpu);
@@ -235,7 +319,7 @@ void adreno_recover(struct msm_gpu *gpu);
 int adreno_submit(struct msm_gpu *gpu, struct msm_gem_submit *submit,
 		struct msm_file_private *ctx);
 void adreno_flush(struct msm_gpu *gpu);
-void adreno_idle(struct msm_gpu *gpu);
+void drma_idle(struct msm_gpu *gpu);
 #ifdef CONFIG_DEBUG_FS
 void adreno_show(struct msm_gpu *gpu, struct seq_file *m);
 #endif
@@ -247,6 +331,13 @@ int adreno_gpu_init(struct drm_device *drm, struct platform_device *pdev,
 		struct adreno_gpu *gpu, const struct adreno_gpu_funcs *funcs);
 void adreno_gpu_cleanup(struct adreno_gpu *gpu);
 
+static inline uint calc_odd_parity_bit(uint val)
+{
+	return (0x9669 >> (0xf & ((val) ^
+	((val) >> 4) ^ ((val) >> 8) ^ ((val) >> 12) ^
+	((val) >> 16) ^ ((val) >> 20) ^ ((val) >> 24) ^
+	((val) >> 28)))) & 1;
+}
 
 /* ringbuffer helpers (the parts that are adreno specific) */
 
@@ -265,11 +356,66 @@ OUT_PKT2(struct msm_ringbuffer *ring)
 	OUT_RING(ring, CP_TYPE2_PKT);
 }
 
+static inline uint
+cp_pkt3(uint8_t opcode, uint16_t cnt)
+{
+	return CP_TYPE3_PKT | ((cnt-1) << 16) | ((opcode & 0xFF) << 8);
+}
+
+static inline uint
+cp_pkt4(uint32_t offset, uint16_t cnt)
+{
+	return CP_TYPE4_PKT | ((cnt) << 0) |
+			(calc_odd_parity_bit(cnt) << 7) |
+			(((offset) & 0x3FFFF) << 8) |
+			((calc_odd_parity_bit(offset) << 27));
+}
+
+static inline uint
+cp_pkt7(uint8_t opcode, uint16_t cnt)
+{
+	return CP_TYPE7_PKT | ((cnt) << 0) |
+			(calc_odd_parity_bit(cnt) << 15) |
+			(((opcode) & 0x7F) << 16) |
+			((calc_odd_parity_bit(opcode) << 23));
+}
+
+static inline uint
+cp_pkt(struct adreno_gpu *adreno_gpu, uint8_t opcode, uint16_t cnt)
+{
+	if (adreno_pre_a5xx(adreno_gpu))
+		return cp_pkt3(opcode, cnt);
+	else
+		return cp_pkt7(opcode, cnt);
+}
+
 static inline void
 OUT_PKT3(struct msm_ringbuffer *ring, uint8_t opcode, uint16_t cnt)
 {
 	adreno_wait_ring(ring->gpu, cnt+1);
-	OUT_RING(ring, CP_TYPE3_PKT | ((cnt-1) << 16) | ((opcode & 0xFF) << 8));
+	OUT_RING(ring, cp_pkt3(opcode, cnt));
+}
+
+static inline void
+OUT_PKT4(struct msm_ringbuffer *ring, uint8_t offset, uint16_t cnt)
+{
+	adreno_wait_ring(ring->gpu, cnt+1);
+	OUT_RING(ring, cp_pkt7(offset, cnt));
+}
+
+static inline void
+OUT_PKT7(struct msm_ringbuffer *ring, uint opcode, uint cnt)
+{
+	adreno_wait_ring(ring->gpu, cnt+1);
+	OUT_RING(ring, cp_pkt7(opcode, cnt));
+
+}
+
+static inline void
+OUT_PKT(struct adreno_gpu *device, struct msm_ringbuffer *ring,
+		uint opcode, uint cnt)
+{
+	OUT_RING(ring, cp_pkt(device, opcode, cnt));
 }
 
 /*
@@ -280,11 +426,26 @@ OUT_PKT3(struct msm_ringbuffer *ring, uint8_t opcode, uint16_t cnt)
 static inline bool adreno_reg_check(struct adreno_gpu *gpu,
 		enum adreno_regs offset_name)
 {
-	if (offset_name >= REG_ADRENO_REGISTER_MAX ||
-			!gpu->reg_offsets[offset_name]) {
-		BUG();
+	if (offset_name > REG_ADRENO_REGISTER_MAX) {
+		pr_warn("offset_name:%d\n", offset_name);
+		pr_warn("REG_MAX:%d\n", REG_ADRENO_REGISTER_MAX);
+		goto error;
+	}
+
+	if (!gpu->reg_offsets[offset_name]) {
+		pr_warn("the offset:%d is null!\n", offset_name);
+		goto error;
 	}
+
 	return true;
+error:
+	BUG();
+}
+
+static inline u32 adreno_gpu_off(struct adreno_gpu *gpu,
+		enum adreno_regs offset_name)
+{
+	return gpu->reg_offsets[offset_name];
 }
 
 static inline u32 adreno_gpu_read(struct adreno_gpu *gpu,
@@ -292,7 +453,8 @@ static inline u32 adreno_gpu_read(struct adreno_gpu *gpu,
 {
 	u32 reg = gpu->reg_offsets[offset_name];
 	u32 val = 0;
-	if(adreno_reg_check(gpu,offset_name))
+
+	if (adreno_reg_check(gpu, offset_name))
 		val = gpu_read(&gpu->base, reg - 1);
 	return val;
 }
@@ -301,8 +463,31 @@ static inline void adreno_gpu_write(struct adreno_gpu *gpu,
 		enum adreno_regs offset_name, u32 data)
 {
 	u32 reg = gpu->reg_offsets[offset_name];
-	if(adreno_reg_check(gpu, offset_name))
+
+	if (adreno_reg_check(gpu, offset_name))
 		gpu_write(&gpu->base, reg - 1, data);
 }
 
+
+static inline u64 adreno_gpu_read64(struct adreno_gpu *gpu,
+		enum adreno_regs offset_l,
+		enum adreno_regs offset_h)
+{
+	u32 reg;
+	u32 vall = 0;
+	u32 valh = 0;
+
+	if (adreno_reg_check(gpu, offset_l)) {
+		reg = gpu->reg_offsets[offset_l];
+		vall = gpu_read(&gpu->base, reg - 1);
+	}
+
+	if (adreno_reg_check(gpu, offset_h)) {
+		reg = gpu->reg_offsets[offset_h];
+		valh = gpu_read(&gpu->base, reg - 1);
+	}
+
+	return vall || ((u64)valh << 32);
+}
+
 #endif /* __ADRENO_GPU_H__ */
diff --git a/drivers/gpu/drm/msm/adreno/adreno_pm4.xml.h b/drivers/gpu/drm/msm/adreno/adreno_pm4.xml.h
index 7c2451b..38bcbb6 100644
--- a/drivers/gpu/drm/msm/adreno/adreno_pm4.xml.h
+++ b/drivers/gpu/drm/msm/adreno/adreno_pm4.xml.h
@@ -105,9 +105,10 @@ enum pc_di_vis_cull_mode {
 
 enum adreno_pm4_packet_type {
 	CP_TYPE0_PKT = 0,
-	CP_TYPE1_PKT = 0x40000000,
 	CP_TYPE2_PKT = 0x80000000,
 	CP_TYPE3_PKT = 0xc0000000,
+	CP_TYPE4_PKT = 0x40000000,
+	CP_TYPE7_PKT = 0x70000000,
 };
 
 enum adreno_pm4_type3_packets {
-- 
1.9.1

