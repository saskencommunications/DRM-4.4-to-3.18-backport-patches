From a584b72f7594d86a4a34c5c8ea9456facbbc21aa Mon Sep 17 00:00:00 2001
From: Yajun Li <yajunl@codeaurora.org>
Date: Sat, 11 Jun 2016 04:10:39 +0800
Subject: [PATCH 05/10] drm:msm move GEM back buffer from SHMEM to DMA

reason: if allocate ring buffer in SHMEM, gpu hang.

Change-Id: Ibfc874ef2e5b427f8a61dbc676be1481cd7a9ca9
Signed-off-by: Yajun Li <yajunl@codeaurora.org>
---
 drivers/gpu/drm/msm/msm_gem.c | 125 +++++++++++++++++++++++++++++++++++-------
 drivers/gpu/drm/msm/msm_gem.h |   7 ++-
 include/uapi/drm/msm_drm.h    |   5 +-
 3 files changed, 114 insertions(+), 23 deletions(-)

diff --git a/drivers/gpu/drm/msm/msm_gem.c b/drivers/gpu/drm/msm/msm_gem.c
index 6b1db50..fc12cf8 100644
--- a/drivers/gpu/drm/msm/msm_gem.c
+++ b/drivers/gpu/drm/msm/msm_gem.c
@@ -68,6 +68,99 @@ static struct page **get_pages_vram(struct drm_gem_object *obj,
 	return p;
 }
 
+static int msm_drm_alloc_buf(struct drm_gem_object *obj)
+{
+	struct msm_gem_object *msm_obj = to_msm_bo(obj);
+	enum dma_attr attr;
+	unsigned int nr_pages;
+	struct page **p = NULL;
+	struct drm_device *dev = obj->dev;
+	struct msm_gem_buf *buf;
+
+	if (msm_obj->buf)
+		return 0;
+
+	buf = kzalloc(sizeof(*buf), GFP_KERNEL);
+	if (!buf) {
+		DRM_ERROR("%s: kzalloc failed\n", __func__);
+		return -ENOMEM;
+	}
+
+	init_dma_attrs(&buf->dma_attrs);
+
+	if (msm_obj->flags & MSM_BO_CONTIGUOUS)
+		dma_set_attr(DMA_ATTR_FORCE_CONTIGUOUS, &buf->dma_attrs);
+
+	if (msm_obj->flags & (MSM_BO_UNCACHED | MSM_BO_WC))
+		attr = DMA_ATTR_WRITE_COMBINE;
+	else
+		attr = DMA_ATTR_NON_CONSISTENT;
+
+	dma_set_attr(attr, &buf->dma_attrs);
+	dma_set_attr(DMA_ATTR_NO_KERNEL_MAPPING, &buf->dma_attrs);
+
+	nr_pages = obj->size >> PAGE_SHIFT;
+
+	p = dma_alloc_attrs(dev->dev, obj->size,
+				&buf->dma_addr, GFP_KERNEL, &buf->dma_attrs);
+	if (!p) {
+		DRM_ERROR("failed to allocate buffer.\n");
+		kfree(buf);
+		return -ENOMEM;
+	}
+
+	msm_obj->buf = buf;
+	msm_obj->pages = p;
+	return 0;
+}
+
+static int msm_drm_free_buf(struct drm_gem_object *obj)
+{
+	struct msm_gem_object *msm_obj = to_msm_bo(obj);
+	struct msm_gem_buf *buf = msm_obj->buf;
+	struct drm_device *dev = obj->dev;
+
+	if (!buf)
+		return 0;
+
+	dma_free_attrs(dev->dev, obj->size, msm_obj->pages,
+				(dma_addr_t)buf->dma_addr, &buf->dma_attrs);
+
+	kfree(buf);
+	msm_obj->buf = NULL;
+
+	return 0;
+}
+
+int msm_drm_gem_mmap_buffer(struct drm_gem_object *obj,
+				      struct vm_area_struct *vma)
+{
+	struct msm_gem_object *msm_obj = to_msm_bo(obj);
+	struct msm_gem_buf *buf = msm_obj->buf;
+	struct drm_device *dev = obj->dev;
+	unsigned long vm_size;
+	int ret;
+
+	vma->vm_flags &= ~VM_PFNMAP;
+	vma->vm_pgoff = 0;
+
+	vm_size = vma->vm_end - vma->vm_start;
+
+	/* check if user-requested size is valid. */
+	if (vm_size > obj->size)
+		return -EINVAL;
+
+	ret = dma_mmap_attrs(dev->dev, vma, msm_obj->pages,
+				buf->dma_addr, obj->size,
+				&buf->dma_attrs);
+	if (ret < 0) {
+		DRM_ERROR("failed to mmap.\n");
+		return ret;
+	}
+
+	return 0;
+}
+
 /* called with dev->struct_mutex held */
 static struct page **get_pages(struct drm_gem_object *obj)
 {
@@ -78,9 +171,10 @@ static struct page **get_pages(struct drm_gem_object *obj)
 		struct page **p;
 		int npages = obj->size >> PAGE_SHIFT;
 
-		if (use_pages(obj))
-			p = drm_gem_get_pages(obj);
-		else
+		if (use_pages(obj)) {
+			if (!msm_drm_alloc_buf(obj))
+				p = msm_obj->pages;
+		} else
 			p = get_pages_vram(obj, npages);
 
 		if (IS_ERR(p)) {
@@ -96,13 +190,6 @@ static struct page **get_pages(struct drm_gem_object *obj)
 		}
 
 		msm_obj->pages = p;
-
-		/* For non-cached buffers, ensure the new pages are clean
-		 * because display controller, GPU, etc. are not coherent:
-		 */
-		if (msm_obj->flags & (MSM_BO_WC|MSM_BO_UNCACHED))
-			dma_map_sg(dev->dev, msm_obj->sgt->sgl,
-					msm_obj->sgt->nents, DMA_BIDIRECTIONAL);
 	}
 
 	return msm_obj->pages;
@@ -113,17 +200,11 @@ static void put_pages(struct drm_gem_object *obj)
 	struct msm_gem_object *msm_obj = to_msm_bo(obj);
 
 	if (msm_obj->pages) {
-		/* For non-cached buffers, ensure the new pages are clean
-		 * because display controller, GPU, etc. are not coherent:
-		 */
-		if (msm_obj->flags & (MSM_BO_WC|MSM_BO_UNCACHED))
-			dma_unmap_sg(obj->dev->dev, msm_obj->sgt->sgl,
-					msm_obj->sgt->nents, DMA_BIDIRECTIONAL);
 		sg_free_table(msm_obj->sgt);
 		kfree(msm_obj->sgt);
 
 		if (use_pages(obj))
-			drm_gem_put_pages(obj, msm_obj->pages, true, false);
+			msm_drm_free_buf(obj);
 		else {
 			drm_mm_remove_node(msm_obj->vram_node);
 			drm_free_large(msm_obj->pages);
@@ -323,9 +404,13 @@ int msm_gem_get_iova_locked(struct drm_gem_object *obj, int id,
 				}
 				msm_obj->domain[id].iova = pa;
 			} else {
+				if (msm_obj->flags & (MSM_BO_WC|MSM_BO_UNCACHED))
+					dma_map_sg(mmu->dev, msm_obj->sgt->sgl,
+							msm_obj->sgt->nents, DMA_BIDIRECTIONAL);
 				msm_obj->domain[id].iova =
 					sg_dma_address(msm_obj->sgt->sgl);
 			}
+			dev_dbg(mmu->dev, "iova=0x%lx\n", msm_obj->domain[id].iova);
 		} else {
 			WARN(1, "physical address being used\n");
 			msm_obj->domain[id].iova = physaddr(obj);
@@ -557,10 +642,8 @@ void msm_gem_free_object(struct drm_gem_object *obj)
 				mmu->funcs->unmap(mmu, offset, msm_obj->sgt,
 					obj->size);
 			} else {
-			/*
-				mmu->funcs->unmap_sg(mmu, msm_obj->sgt,
-						DMA_BIDIRECTIONAL);
-			*/
+				dma_unmap_sg(mmu->dev, msm_obj->sgt->sgl,
+					msm_obj->sgt->nents, DMA_BIDIRECTIONAL);
 			}
 		}
 	}
diff --git a/drivers/gpu/drm/msm/msm_gem.h b/drivers/gpu/drm/msm/msm_gem.h
index aa36946..4dab85f 100644
--- a/drivers/gpu/drm/msm/msm_gem.h
+++ b/drivers/gpu/drm/msm/msm_gem.h
@@ -24,9 +24,14 @@
 /* Additional internal-use only BO flags: */
 #define MSM_BO_STOLEN        0x10000000    /* try to use stolen/splash memory */
 
+struct msm_gem_buf {
+	dma_addr_t dma_addr;
+	struct dma_attrs dma_attrs;
+};
+
 struct msm_gem_object {
 	struct drm_gem_object base;
-
+	struct msm_gem_buf *buf;
 	uint32_t flags;
 
 	/* And object is either:
diff --git a/include/uapi/drm/msm_drm.h b/include/uapi/drm/msm_drm.h
index 9ae5074..d350ba5 100644
--- a/include/uapi/drm/msm_drm.h
+++ b/include/uapi/drm/msm_drm.h
@@ -70,11 +70,14 @@ struct drm_msm_param {
 #define MSM_BO_WC            0x00020000
 #define MSM_BO_UNCACHED      0x00040000
 
+#define MSM_BO_CONTIGUOUS    0x00100000
+
 #define MSM_BO_FLAGS         (MSM_BO_SCANOUT | \
                               MSM_BO_GPU_READONLY | \
                               MSM_BO_CACHED | \
                               MSM_BO_WC | \
-                              MSM_BO_UNCACHED)
+                              MSM_BO_UNCACHED | \
+							  MSM_BO_CONTIGUOUS)
 
 struct drm_msm_gem_new {
 	__u64 size;           /* in */
-- 
1.9.1

